# üîç Anomaly Flow

> **Solution de Monitoring Temps R√©el : Data Quality & D√©tection d'Anomalies**

[![Python 3.12](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![Kafka](https://img.shields.io/badge/Kafka-Redpanda-red.svg)](https://redpanda.com/)
[![Prometheus](https://img.shields.io/badge/Monitoring-Prometheus-orange.svg)](https://prometheus.io/)
[![Grafana](https://img.shields.io/badge/Dashboard-Grafana-green.svg)](https://grafana.com/)

---

## üìã Table des mati√®res

- [Pr√©sentation](#-pr√©sentation)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Architecture](#Ô∏è-architecture)
- [D√©marrage rapide](#-d√©marrage-rapide)
- [Composants du syst√®me](#-composants-du-syst√®me)
- [M√©triques et monitoring](#-m√©triques-et-monitoring)
- [Configuration](#-configuration)
- [D√©tection d'anomalies](#-d√©tection-danomalies)
- [Contr√¥les Data Quality](#-contr√¥les-data-quality)
- [Alerting](#-alerting)
- [D√©pendances](#-d√©pendances)
- [D√©veloppement](#Ô∏è-d√©veloppement)
- [Troubleshooting](#-troubleshooting)

---

## üéØ Pr√©sentation

**Anomaly Flow** est une plateforme compl√®te de monitoring temps r√©el con√ßue pour :

1. **Ing√©rer des flux de donn√©es** via Apache Kafka (impl√©ment√© avec Redpanda)
2. **Valider la qualit√© des donn√©es** en temps r√©el (sch√©ma, valeurs, fra√Æcheur)
3. **D√©tecter les anomalies** avec des algorithmes de Machine Learning streaming
4. **Exposer des m√©triques** pour Prometheus et visualiser dans Grafana
5. **Alerter** en cas de probl√®me (anomalies, erreurs de qualit√©)

Cette solution est id√©ale pour :
- Monitoring de capteurs IoT
- Surveillance de syst√®mes de production
- D√©tection de fraudes en temps r√©el
- Observabilit√© de pipelines de donn√©es

---

## ‚ú® Fonctionnalit√©s

### üîÑ Ingestion Streaming
- **Kafka API** via Redpanda (l√©ger, compatible Kafka)
- Consommation en temps r√©el avec auto-commit
- S√©rialisation JSON optimis√©e avec `orjson`

### üìä Contr√¥les Data Quality
| Contr√¥le | Description |
|----------|-------------|
| **Sch√©ma** | Validation Pydantic (champs requis, types) |
| **Valeurs nulles** | D√©tection des champs manquants obligatoires |
| **Intervalles** | V√©rification que les valeurs sont dans les bornes acceptables |
| **Fra√Æcheur** | Rejet des √©v√©nements trop anciens (> 5 min par d√©faut) |

### ü§ñ D√©tection d'Anomalies
- **Algorithme** : Half-Space Trees (River ML)
- **Apprentissage en ligne** : le mod√®le s'adapte en continu
- **Seuil dynamique** : bas√© sur le quantile 99.5% des scores
- **Sans supervision** : pas besoin de donn√©es √©tiquet√©es

### üìà Observabilit√©
- **M√©triques Prometheus** expos√©es sur `:8000/metrics`
- **Dashboard Grafana** pr√©-provisionn√©
- **Alertes** configurables (taux d'anomalies, erreurs DQ)

---

## üèóÔ∏è Architecture

```
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ              ANOMALY FLOW SYSTEM                ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                 ‚îÇ         ‚îÇ                 ‚îÇ         ‚îÇ                         ‚îÇ
    ‚îÇ    GENERATOR    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    REDPANDA     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ       PROCESSOR         ‚îÇ
    ‚îÇ                 ‚îÇ         ‚îÇ    (Kafka)      ‚îÇ         ‚îÇ                         ‚îÇ
    ‚îÇ  src/generator  ‚îÇ         ‚îÇ                 ‚îÇ         ‚îÇ    src/processor        ‚îÇ
    ‚îÇ                 ‚îÇ         ‚îÇ   Topic:events  ‚îÇ         ‚îÇ                         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                           ‚îÇ                                ‚îÇ
           ‚îÇ                           ‚îÇ                                ‚îÇ
           ‚îÇ ~20 events/sec            ‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ                           ‚îÇ                    ‚îÇ                       ‚îÇ
           ‚ñº                           ‚ñº                    ‚ñº                       ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Simule des     ‚îÇ         ‚îÇ   Topic:alerts  ‚îÇ  ‚îÇ Prometheus  ‚îÇ        ‚îÇ   Grafana   ‚îÇ
    ‚îÇ  capteurs IoT   ‚îÇ         ‚îÇ   (anomalies)   ‚îÇ  ‚îÇ   :9090     ‚îÇ        ‚îÇ   :3000     ‚îÇ
    ‚îÇ                 ‚îÇ         ‚îÇ                 ‚îÇ  ‚îÇ             ‚îÇ        ‚îÇ             ‚îÇ
    ‚îÇ ‚Ä¢ Valeurs norm. ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ ‚Ä¢ Scrape    ‚îÇ        ‚îÇ ‚Ä¢ Dashboard ‚îÇ
    ‚îÇ ‚Ä¢ Anomalies 2%  ‚îÇ                              ‚îÇ ‚Ä¢ Alerting  ‚îÇ        ‚îÇ ‚Ä¢ Graphes   ‚îÇ
    ‚îÇ ‚Ä¢ Erreurs DQ 1% ‚îÇ                              ‚îÇ ‚Ä¢ Stockage  ‚îÇ        ‚îÇ ‚Ä¢ Temps r√©el‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    FLUX DE DONN√âES :

    1. Generator ‚Üí Produit des √©v√©nements JSON simulant des capteurs
    2. Redpanda  ‚Üí Buffer les messages dans le topic "events"
    3. Processor ‚Üí Consomme, valide, d√©tecte les anomalies
    4. Processor ‚Üí Expose les m√©triques sur :8000/metrics
    5. Processor ‚Üí Publie les alertes sur le topic "alerts"
    6. Prometheus ‚Üí Scrape les m√©triques toutes les 5s
    7. Grafana   ‚Üí Visualise en temps r√©el
```

### Flux de donn√©es d√©taill√©

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     JSON Event      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    Validated     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ            ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ            ‚îÇ
‚îÇ  Capteur   ‚îÇ  {                  ‚îÇ   Schema   ‚îÇ                  ‚îÇ  DQ Checks ‚îÇ
‚îÇ  (Source)  ‚îÇ    sensor_id,       ‚îÇ Validation ‚îÇ                  ‚îÇ            ‚îÇ
‚îÇ            ‚îÇ    ts, value,       ‚îÇ  (Pydantic)‚îÇ                  ‚îÇ ‚Ä¢ Required ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    temperature      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ ‚Ä¢ Range    ‚îÇ
                  }                      ‚îÇ                         ‚îÇ ‚Ä¢ Freshness‚îÇ
                                         ‚îÇ Invalid                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                         ‚ñº                               ‚îÇ
                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ Valid
                                 ‚îÇ dq_records_   ‚îÇ                       ‚ñº
                                 ‚îÇ total{invalid}‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ                ‚îÇ
                                                                ‚îÇ Anomaly        ‚îÇ
                                                                ‚îÇ Detection      ‚îÇ
                                                                ‚îÇ                ‚îÇ
                                                                ‚îÇ ‚Ä¢ HST Model    ‚îÇ
                                                                ‚îÇ ‚Ä¢ Score        ‚îÇ
                                                                ‚îÇ ‚Ä¢ Threshold    ‚îÇ
                                                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                        ‚îÇ
                                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                         ‚îÇ                                     ‚îÇ
                                         ‚ñº                                     ‚ñº
                                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                 ‚îÇ  Normal       ‚îÇ                    ‚îÇ  ANOMALY!      ‚îÇ
                                 ‚îÇ               ‚îÇ                    ‚îÇ                ‚îÇ
                                 ‚îÇ last_anomaly_ ‚îÇ                    ‚îÇ anomalies_total‚îÇ
                                 ‚îÇ score (Gauge) ‚îÇ                    ‚îÇ + alert topic  ‚îÇ
                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ D√©marrage rapide

### Pr√©requis

- **GitHub Codespaces** (recommand√©) ou Docker + Python 3.12 local
- Ports disponibles : 3000, 8000, 9090, 9092

### √âtape 1 : Ouvrir dans GitHub Codespaces

1. Allez sur le repository GitHub
2. Cliquez sur **Code** ‚Üí **Codespaces** ‚Üí **Create codespace on main**
3. Attendez que l'environnement se construise (~2-3 min)

### √âtape 2 : D√©marrer les services Docker

```bash
# Depuis la racine du projet
cd .devcontainer && docker compose up -d redpanda prometheus grafana
```

**V√©rifier que les services sont lanc√©s :**
```bash
docker compose ps
```

R√©sultat attendu :
```
NAME                        STATUS
devcontainer-grafana-1      Up
devcontainer-prometheus-1   Up
devcontainer-redpanda-1     Up
```

### √âtape 3 : Configurer l'environnement Python

```bash
# Revenir √† la racine
cd /workspaces/Anomaly_flow

# Cr√©er l'environnement virtuel
python3 -m venv .venv

# Activer l'environnement
source .venv/bin/activate

# Installer les d√©pendances
pip install --upgrade pip
pip install -r requirements.txt
```

### √âtape 4 : Lancer le Processeur (Terminal 1)

```bash
source .venv/bin/activate
KAFKA_BROKER=localhost:9092 python -m src.processor
```

**Output attendu :**
```
2026-01-02 10:00:00 [info] metrics_server_started port=8000
2026-01-02 10:00:01 [info] processor_started broker=localhost:9092 topic=events
```

### √âtape 5 : Lancer le G√©n√©rateur (Terminal 2)

```bash
source .venv/bin/activate
KAFKA_BROKER=localhost:9092 python -m src.generator
```

**Output attendu :**
```
Generator connected to localhost:9092, topic=events
```

### √âtape 6 : Acc√©der aux interfaces

| Service | URL | Identifiants |
|---------|-----|--------------|
| **Grafana** | http://localhost:3000 | Acc√®s anonyme (pas de login) |
| **Prometheus** | http://localhost:9090 | - |
| **Prometheus Targets** | http://localhost:9090/targets | V√©rifier que le target est "UP" |
| **Prometheus Alerts** | http://localhost:9090/alerts | Voir les alertes actives |
| **Alertmanager** | http://localhost:9093 | Gestion des notifications |
| **Metrics brutes** | http://localhost:8000/metrics | Endpoint Prometheus du processeur |

---

## ÔøΩ Commandes rapides

### ‚ñ∂Ô∏è Tout d√©marrer

```bash
# 1. D√©marrer les services Docker
cd /workspaces/Anomaly_flow/.devcontainer && docker compose up -d

# 2. Lancer le processor (Terminal 1)
cd /workspaces/Anomaly_flow && source .venv/bin/activate
KAFKA_BROKER=localhost:9092 python -m src.processor

# 3. Lancer le generator (Terminal 2)
cd /workspaces/Anomaly_flow && source .venv/bin/activate
KAFKA_BROKER=localhost:9092 python -m src.generator

# 4. (Optionnel) Lancer le consumer d'alertes avec email (Terminal 3)
cd /workspaces/Anomaly_flow && source .venv/bin/activate
KAFKA_BROKER=localhost:9092 \
SMTP_ENABLED=true \
SMTP_HOST=smtp.gmail.com \
SMTP_PORT=587 \
SMTP_USER=votre-email@gmail.com \
SMTP_PASSWORD=votre-app-password \
EMAIL_TO=destinataire@example.com \
python -m src.alert_consumer
```

### ‚èπÔ∏è Tout arr√™ter

```bash
# Arr√™ter les processus Python et les services Docker
cd /workspaces/Anomaly_flow && pkill -f "python -m src" 2>/dev/null
cd .devcontainer && docker compose down
```

### üîÑ Red√©marrer uniquement les services Docker

```bash
cd /workspaces/Anomaly_flow/.devcontainer && docker compose restart
```

### üìä V√©rifier l'√©tat des services

```bash
# Services Docker
cd /workspaces/Anomaly_flow/.devcontainer && docker compose ps

# Processus Python
ps aux | grep "python -m src"
```

---

## ÔøΩüîß Composants du syst√®me

### Generator (`src/generator.py`)

Le g√©n√©rateur simule des capteurs IoT en produisant ~20 √©v√©nements/seconde.

**Structure d'un √©v√©nement :**
```json
{
  "sensor_id": "sensor-0",
  "ts": 1767347851.123,
  "value": 1.2345,
  "temperature": 24.5,
  "status": "OK"
}
```

**Injection de donn√©es anormales :**
| Type | Probabilit√© | Description |
|------|-------------|-------------|
| Anomalie valeur | 2% | `value` avec offset ¬±25 ou ¬±50 |
| Anomalie temp√©rature | 1% | `temperature` avec offset ¬±20/30 |
| Champ manquant | 0.5% | Suppression du champ `value` |
| Valeur hors range | 0.5% | `value = 9999` |
| √âv√©nement ancien | 0.5% | `ts` = il y a 3 jours |

### Processor (`src/processor.py`)

Le c≈ìur du syst√®me qui :

1. **Consomme** les messages Kafka du topic `events`
2. **Valide** le sch√©ma avec Pydantic
3. **Ex√©cute** les contr√¥les Data Quality
4. **Calcule** le score d'anomalie avec Half-Space Trees
5. **Met √† jour** les m√©triques Prometheus
6. **Publie** les alertes sur le topic `alerts`

**Logs de progression :**
```
[info] progress processed=1000 anomalies=15 last_score=0.65 threshold=0.999
```

### Schema (`src/schema.py`)

D√©finition Pydantic du sch√©ma d'√©v√©nement :

```python
class Event(BaseModel):
    sensor_id: str          # Identifiant du capteur (obligatoire)
    ts: float               # Timestamp Unix en secondes
    value: float            # Valeur mesur√©e (obligatoire)
    temperature: float      # Temp√©rature (optionnel)
    status: str = "OK"      # Statut : OK, WARN, FAIL
```

**Validations automatiques :**
- `sensor_id` : minimum 1 caract√®re
- `ts` : doit √™tre dans une fen√™tre de ¬±1 jour
- `status` : doit √™tre "OK", "WARN" ou "FAIL"

---

## üìä M√©triques et Monitoring

### M√©triques Prometheus expos√©es

| M√©trique | Type | Labels | Description |
|----------|------|--------|-------------|
| `processed_records_total` | Counter | - | Nombre total d'√©v√©nements trait√©s |
| `dq_records_total` | Counter | `outcome`, `check` | R√©sultats des contr√¥les qualit√© |
| `anomalies_total` | Counter | - | Nombre d'anomalies d√©tect√©es |
| `last_anomaly_score` | Gauge | - | Score de la derni√®re anomalie (0-1) |
| `anomaly_threshold` | Gauge | - | Seuil dynamique actuel (quantile 99.5%) |
| `event_value` | Histogram | - | Distribution des valeurs `value` |

### Exemples de requ√™tes PromQL

```promql
# Taux de traitement (events/sec)
rate(processed_records_total[1m])

# Taux d'anomalies (anomalies/sec)
rate(anomalies_total[1m])

# Pourcentage d'√©v√©nements invalides
sum(rate(dq_records_total{outcome="invalid"}[5m])) 
/ 
sum(rate(dq_records_total[5m])) * 100

# Score d'anomalie actuel vs seuil
last_anomaly_score / anomaly_threshold

# √âv√©nements invalides par type de contr√¥le
sum by (check) (increase(dq_records_total{outcome="invalid"}[5m]))
```

### Dashboard Grafana

Le dashboard pr√©-provisionn√© inclut :

| Panel | Description |
|-------|-------------|
| **Events Processed** | Compteur total d'√©v√©nements trait√©s |
| **Anomalies Detected** | Compteur total d'anomalies |
| **Processing Rate** | Graphe du d√©bit (events/sec) |
| **Anomaly Score** | Score actuel vs seuil dynamique |
| **DQ Errors** | R√©partition des erreurs par type |
| **Value Distribution** | Histogramme des valeurs |

---

## ‚öôÔ∏è Configuration

### Variables d'environnement

| Variable | D√©faut | Description |
|----------|--------|-------------|
| `KAFKA_BROKER` | `redpanda:9092` | Adresse du broker Kafka |
| `TOPIC_EVENTS` | `events` | Topic d'entr√©e des √©v√©nements |
| `TOPIC_ALERTS` | `alerts` | Topic de sortie des alertes |

### Param√®tres (`src/config.py`)

```python
@dataclass
class Settings:
    # Kafka
    kafka_broker: str = "redpanda:9092"
    topic_events: str = "events"
    topic_alerts: str = "alerts"

    # Data Quality - Intervalles acceptables
    value_range = (-100.0, 100.0)       # Bornes pour 'value'
    temperature_range = (-20.0, 80.0)   # Bornes pour 'temperature'
    freshness_max_lag_sec = 300.0       # Max 5 minutes de retard

    # Anomaly Detection - Half-Space Trees
    quantile_p = 0.995      # Seuil = quantile 99.5% des scores
    hst_n_trees = 25        # Nombre d'arbres
    hst_height = 15         # Profondeur des arbres
    hst_window_size = 250   # Taille de la fen√™tre glissante
```

### Personnaliser les seuils

**Exemple : R√©duire la sensibilit√© aux anomalies**
```python
# Dans src/config.py
quantile_p = 0.999  # Seulement le top 0.1% sera consid√©r√© anomalie
```

**Exemple : √âlargir les intervalles acceptables**
```python
value_range = (-500.0, 500.0)
temperature_range = (-50.0, 100.0)
```

---

## ü§ñ D√©tection d'Anomalies

### Algorithme : Half-Space Trees (HST)

**Principe :**
- Algorithme de for√™t al√©atoire pour la d√©tection d'anomalies en streaming
- Pas besoin d'entra√Ænement pr√©alable
- S'adapte en continu aux donn√©es
- Complexit√© O(1) par √©v√©nement

**Fonctionnement :**
1. Chaque arbre partitionne l'espace des features al√©atoirement
2. Les points "normaux" tombent dans des r√©gions denses
3. Les anomalies tombent dans des r√©gions peu peupl√©es
4. Le score = moyenne des scores de tous les arbres

### Seuil dynamique

Au lieu d'un seuil fixe, nous utilisons le **quantile 99.5%** des scores historiques :

```
Score > Quantile(99.5%) ‚Üí ANOMALIE
```

**Avantages :**
- S'adapte automatiquement √† la distribution des donn√©es
- Pas besoin de calibration manuelle
- Robuste aux changements de r√©gime

### Features utilis√©es

| Feature | Source | Description |
|---------|--------|-------------|
| `value` | √âv√©nement | Valeur principale du capteur |
| `temperature` | √âv√©nement | Temp√©rature (si pr√©sente) |

---

## ‚úÖ Contr√¥les Data Quality

### Liste des contr√¥les

| Contr√¥le | Code | Condition de rejet |
|----------|------|-------------------|
| **Champs requis** | `required` | `sensor_id`, `ts`, ou `value` manquant |
| **Intervalle value** | `range_value` | `value` hors [-100, 100] |
| **Intervalle temperature** | `range_temperature` | `temperature` hors [-20, 80] |
| **Fra√Æcheur** | `freshness` | `ts` > 5 minutes dans le pass√© |

### M√©triques DQ

```promql
# Total des erreurs par type
dq_records_total{outcome="invalid", check="schema"}
dq_records_total{outcome="invalid", check="range_value"}
dq_records_total{outcome="invalid", check="freshness"}

# √âv√©nements valides
dq_records_total{outcome="ok", check="all"}
```

---

## üö® Alerting

### R√®gles Prometheus (`prometheus/alerts.yml`)

#### 1. HighAnomalyRate
```yaml
alert: HighAnomalyRate
expr: rate(anomalies_total[1m]) > 0.1
for: 30s
severity: warning
```
**D√©clench√© quand :** Plus de 0.1 anomalie/seconde pendant 30s

#### 2. DataQualityErrors
```yaml
alert: DataQualityErrors
expr: increase(dq_records_total{outcome="invalid"}[1m]) > 0
for: 0s
severity: critical
```
**D√©clench√© quand :** Toute erreur DQ dans la derni√®re minute

### Alertes publi√©es sur Kafka

Chaque anomalie g√©n√®re un message sur le topic `alerts` :

```json
{
  "type": "anomaly",
  "sensor_id": "sensor-2",
  "ts": 1767347851.123,
  "score": 0.9998,
  "threshold": 0.9995,
  "features": {
    "value": 52.34,
    "temperature": 25.1
  },
  "dq_issues": []
}
```

### Consommateur d'alertes (`src/alert_consumer.py`)

Un script d√©di√© permet de consommer les alertes Kafka et d'envoyer des notifications :

```bash
# Affichage console uniquement
KAFKA_BROKER=localhost:9092 python -m src.alert_consumer
```

**Output :**
```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üö® ANOMALIE D√âTECT√âE                                        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  Capteur    : sensor-2                                       ‚ïë
‚ïë  Timestamp  : 2026-01-02 14:30:45                           ‚ïë
‚ïë  Score      : 0.6523 (seuil: 0.5891)                        ‚ïë
‚ïë  Features   : value=52.34, temperature=25.1                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

### Notifications Slack

1. **Cr√©er une app Slack** : https://api.slack.com/apps
2. **Activer Incoming Webhooks** et cr√©er un webhook pour votre channel
3. **Lancer le consumer avec le webhook** :

```bash
KAFKA_BROKER=localhost:9092 \
SLACK_WEBHOOK_URL="https://hooks.slack.com/services/XXX/YYY/ZZZ" \
python -m src.alert_consumer
```

### Notifications Email (Gmail)

#### Pr√©requis : Cr√©er un App Password Gmail

1. Activez la **V√©rification en 2 √©tapes** : https://myaccount.google.com/signinoptions/two-step-verification
2. Cr√©ez un **Mot de passe d'application** : https://myaccount.google.com/apppasswords
   - S√©lectionnez "Autre (nom personnalis√©)" ‚Üí "Anomaly Flow"
   - Copiez le code √† 16 caract√®res

#### Lancer avec notifications Email

```bash
KAFKA_BROKER=localhost:9092 \
SMTP_ENABLED=true \
SMTP_HOST=smtp.gmail.com \
SMTP_PORT=587 \
SMTP_USER=votre-email@gmail.com \
SMTP_PASSWORD=xxxx-xxxx-xxxx-xxxx \
EMAIL_TO=destinataire@example.com \
python -m src.alert_consumer
```

#### Tester la configuration Email

```bash
SMTP_HOST=smtp.gmail.com \
SMTP_PORT=587 \
SMTP_USER=votre-email@gmail.com \
SMTP_PASSWORD=xxxx-xxxx-xxxx-xxxx \
EMAIL_TO=destinataire@example.com \
python -m src.test_email
```

#### Autres serveurs SMTP

| Provider | Host | Port |
|----------|------|------|
| Gmail | smtp.gmail.com | 587 |
| Outlook | smtp.office365.com | 587 |
| Yahoo | smtp.mail.yahoo.com | 587 |
| SendGrid | smtp.sendgrid.net | 587 |

### Alertmanager Prometheus (production)

Pour une gestion avanc√©e des alertes en production, Alertmanager est configur√© :

```bash
# D√©marrer Alertmanager
cd .devcontainer && docker compose up -d alertmanager
```

**Acc√®s :** http://localhost:9093

**Configuration :** √âditez `prometheus/alertmanager.yml` pour configurer :
- Routes d'alertes par s√©v√©rit√©
- Groupement d'alertes
- Inhibition des alertes redondantes
- Notifications Slack/Email natives

---

## üì¶ D√©pendances

### Python (`requirements.txt`)

| Package | Version | R√¥le |
|---------|---------|------|
| `kafka-python-ng` | latest | Client Kafka compatible Python 3.12 |
| `pydantic` | 2.8.2 | Validation de sch√©ma et s√©rialisation |
| `prometheus-client` | 0.20.0 | Export des m√©triques |
| `river` | 0.23+ | Machine Learning streaming (Half-Space Trees) |
| `structlog` | 24.1.0 | Logging structur√© JSON |
| `orjson` | 3.10.3 | S√©rialisation JSON haute performance |

### Services Docker

| Service | Image | Port | R√¥le |
|---------|-------|------|------|
| **Redpanda** | `redpandadata/redpanda:v23.3.14` | 9092 | Broker Kafka |
| **Prometheus** | `prom/prometheus:v2.53.0` | 9090 | Collecte m√©triques |
| **Grafana** | `grafana/grafana:11.1.0` | 3000 | Visualisation |
| **Alertmanager** | `prom/alertmanager:v0.27.0` | 9093 | Gestion des alertes |

---

## üõ†Ô∏è D√©veloppement

### Structure du projet

```
Anomaly_flow/
‚îú‚îÄ‚îÄ .devcontainer/
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml      # Services Docker
‚îú‚îÄ‚îÄ grafana/
‚îÇ   ‚îú‚îÄ‚îÄ dashboards/             # JSON des dashboards
‚îÇ   ‚îî‚îÄ‚îÄ provisioning/           # Auto-configuration Grafana
‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml          # Config scraping
‚îÇ   ‚îú‚îÄ‚îÄ alerts.yml              # R√®gles d'alertes
‚îÇ   ‚îî‚îÄ‚îÄ alertmanager.yml        # Config notifications Slack/Email
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ anomaly.py              # D√©tecteur Half-Space Trees
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Param√®tres
‚îÇ   ‚îú‚îÄ‚îÄ generator.py            # G√©n√©rateur d'√©v√©nements
‚îÇ   ‚îú‚îÄ‚îÄ processor.py            # Pipeline principal
‚îÇ   ‚îú‚îÄ‚îÄ quality.py              # Contr√¥les DQ
‚îÇ   ‚îú‚îÄ‚îÄ schema.py               # Sch√©ma Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ alert_consumer.py       # Consumer alertes + notifications
‚îÇ   ‚îî‚îÄ‚îÄ test_email.py           # Test configuration SMTP
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

### Commandes utiles

```bash
# Activer l'environnement
source .venv/bin/activate

# Voir les logs du processeur en temps r√©el
KAFKA_BROKER=localhost:9092 python -m src.processor 2>&1 | head -100

# Tester les m√©triques
curl -s http://localhost:8000/metrics | grep -E "^(processed|anomalies|dq_)"

# V√©rifier Prometheus
curl -s "http://localhost:9090/api/v1/query?query=up"

# Red√©marrer les services Docker
cd .devcontainer && docker compose restart

# Voir les logs Docker
docker compose logs -f prometheus
```

### Tests (√† impl√©menter)

```bash
# Installer pytest
pip install pytest pytest-cov

# Lancer les tests
pytest tests/ -v --cov=src
```

---

## üîß Troubleshooting

### Erreur : `NoBrokersAvailable`

**Cause :** Kafka/Redpanda n'est pas accessible

**Solution :**
```bash
# V√©rifier que Redpanda tourne
docker compose ps

# Relancer si n√©cessaire
cd .devcontainer && docker compose up -d redpanda

# V√©rifier la connectivit√©
nc -zv localhost 9092
```

### Erreur : `Address already in use` (port 8000)

**Cause :** Un autre processus utilise le port

**Solution :**
```bash
# Tuer le processus sur le port
fuser -k 8000/tcp

# Ou trouver le PID
lsof -i :8000
kill <PID>
```

### Prometheus ne scrape pas les m√©triques

**Cause :** Le target n'est pas accessible depuis le container

**Solution :**
1. V√©rifier que `prometheus.yml` pointe vers `host.docker.internal:8000`
2. V√©rifier que `extra_hosts` est configur√© dans `docker-compose.yml`
3. Red√©marrer Prometheus : `docker compose restart prometheus`

### Les donn√©es n'apparaissent pas dans Grafana

**Causes possibles :**
1. Le processeur n'est pas lanc√©
2. Le g√©n√©rateur n'est pas lanc√©
3. Prometheus ne scrape pas

**V√©rifications :**
```bash
# 1. M√©triques expos√©es ?
curl http://localhost:8000/metrics | grep processed

# 2. Prometheus scrape OK ?
curl "http://localhost:9090/api/v1/targets" | python3 -m json.tool

# 3. Donn√©es dans Prometheus ?
curl "http://localhost:9090/api/v1/query?query=processed_records_total"
```

---

## üìù Licence

MIT License - Voir le fichier [LICENSE](LICENSE)

---

## ü§ù Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† :

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/amelioration`)
3. Commit vos changements (`git commit -am 'Ajout fonctionnalit√©'`)
4. Push la branche (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

---

**D√©velopp√© avec ‚ù§Ô∏è pour le monitoring temps r√©el**
